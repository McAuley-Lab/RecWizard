<!doctype html>
<html class="no-js" lang="en" data-content_root="">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" /><link rel="next" title="Llama" href="llama.html" /><link rel="prev" title="General LLM" href="general.html" />

    <!-- Generated with Sphinx 7.1.2 and Furo 2023.09.10 -->
        <title>ChatGPT - RecWizard</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=362ab14a" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../index.html"><div class="brand">RecWizard</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../../../_static/logo.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../../../_static/logo.png" alt="Dark Logo"/>
  </div>
  
  
</a><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">GET STARTED</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../quick_start/concept.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quick_start/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quick_start/example.html">First Example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">USER GUIDE</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../usage/loading/index.html">Use Existing Models</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Use Existing Models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../usage/loading/whole.html">1. CRS Models as a Whole</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../usage/loading/module.html">2. CRS Models at Module Level</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../usage/loading/single.html">3. Single CRS Modules</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../usage/interface/index.html">Interact with Models</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Interact with Models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../usage/interface/launch.html">1. Launch Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../usage/interface/info.html">2. INFO Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../usage/interface/debug.html">3. DEBUG Mode</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../usage/development/index.html">Develop New Models</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Develop New Models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../usage/development/setup.html">1. Tutorial Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../usage/development/recommender.html">2. NEW Recommender</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../usage/development/generator.html">3.  NEW Generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../usage/development/pipeline.html">4. NEW Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../usage/development/interface.html">5. NEW Interactive Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../usage/development/sharing.html">6. Share NEW models</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API REFERENCE</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../baseclass/index.html">Base Classes</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Base Classes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../baseclass/config.html">recwizard.BaseConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../baseclass/tokenizer.html">recwizard.BaseTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../baseclass/module.html">recwizard.BaseModule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../baseclass/pipeline.html">recwizard.BasePipeline</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../pipelines/index.html">Pipelines</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Pipelines</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../pipelines/expansion.html">Expansion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../pipelines/fill_blank.html">FillBlank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../pipelines/switch_decode.html">SwitchDecode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../pipelines/chatgpt.html">ChatGPT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../pipelines/trivial.html">Trivial</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../index.html">Modules</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Modules</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../redial/index.html">ReDIAL</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of ReDIAL</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../redial/recommender.html">Recommender Module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../redial/generator.html">Generator Module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../redial/supporting.html">Supporting Modules</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../kbrd/index.html">KBRD</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of KBRD</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../kbrd/recommender.html">Recommender Module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../kbrd/generator.html">Generator Module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../kbrd/supporting.html">Supporting Modules</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../kgsf/index.html">KGSF</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of KGSF</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../kgsf/recommender.html">Recommender Module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../kgsf/generator.html">Generator Module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../kgsf/supporting.html">Supporting Modules</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../unicrs/index.html">UniCRS</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of UniCRS</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../unicrs/recommender.html">Recommender Module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../unicrs/generator.html">Generator Module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../unicrs/supporting.html">Supporting Modules</a></li>
</ul>
</li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="index.html">LLMs</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of LLMs</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="general.html">General LLM</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">ChatGPT</a></li>
<li class="toctree-l3"><a class="reference internal" href="llama.html">Llama</a></li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="chatgpt">
<h1>ChatGPT<a class="headerlink" href="#chatgpt" title="Permalink to this heading">#</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">recwizard.modules.llm.modeling_chatgpt_gen.</span></span><span class="sig-name descname"><span class="pre">ChatgptGen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="general.html#recwizard.modules.llm.configuration_llm.LLMConfig" title="recwizard.modules.llm.configuration_llm.LLMConfig"><span class="pre">LLMConfig</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/recwizard/modules/llm/modeling_chatgpt_gen.html#ChatgptGen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen" title="Permalink to this definition">#</a></dt>
<dd><p>The generator implemented based on OpanAI’s GPT models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="general.html#recwizard.modules.llm.configuration_llm.LLMConfig" title="recwizard.modules.llm.configuration_llm.LLMConfig"><span class="pre">LLMConfig</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/recwizard/modules/llm/modeling_chatgpt_gen.html#ChatgptGen.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.__init__" title="Permalink to this definition">#</a></dt>
<dd><p>Initializes the instance based on the config file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<em>ChatgptGenConfig</em>) – The config file.</p></li>
<li><p><strong>prompt</strong> (<em>str</em><em>, </em><em>optional</em>) – A prompt to override the prompt from config file.</p></li>
<li><p><strong>model_name</strong> (<em>str</em><em>, </em><em>optional</em>) – The specified GPT model’s name.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.from_pretrained">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained_model_name_or_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/recwizard/modules/llm/modeling_chatgpt_gen.html#ChatgptGen.from_pretrained"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.from_pretrained" title="Permalink to this definition">#</a></dt>
<dd><p>Get an instance of this class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> – </p></li>
<li><p><strong>pretrained_model_name_or_path</strong> – </p></li>
<li><p><strong>prompt</strong> (<em>str</em><em>, </em><em>optional</em>) – The prompt to override the prompt from config file.</p></li>
<li><p><strong>model_name</strong> (<em>str</em><em>, </em><em>optional</em>) – The specified GPT model’s name.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.save_pretrained">
<span class="sig-name descname"><span class="pre">save_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_directory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">PathLike</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">push_to_hub</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/recwizard/modules/llm/modeling_chatgpt_gen.html#ChatgptGen.save_pretrained"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.save_pretrained" title="Permalink to this definition">#</a></dt>
<dd><p>Save a model and its configuration file to a directory, so that it can be re-loaded using the
[<cite>~PreTrainedModel.from_pretrained</cite>] class method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_directory</strong> (<cite>str</cite> or <cite>os.PathLike</cite>) – Directory to which to save. Will be created if it doesn’t exist.</p></li>
<li><p><strong>is_main_process</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>True</cite>) – Whether the process calling this is the main process or not. Useful when in distributed training like
TPUs and need to call this function on all processes. In this case, set <cite>is_main_process=True</cite> only on
the main process to avoid race conditions.</p></li>
<li><p><strong>state_dict</strong> (nested dictionary of <cite>torch.Tensor</cite>) – The state dictionary of the model to save. Will default to <cite>self.state_dict()</cite>, but can be used to only
save parts of the model or if special precautions need to be taken when recovering the state dictionary
of a model (like when using model parallelism).</p></li>
<li><p><strong>save_function</strong> (<cite>Callable</cite>) – The function to use to save the state dictionary. Useful on distributed training like TPUs when one
need to replace <cite>torch.save</cite> by another method.</p></li>
<li><p><strong>push_to_hub</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>) – Whether or not to push your model to the Hugging Face model hub after saving it. You can specify the
repository you want to push to with <cite>repo_id</cite> (will default to the name of <cite>save_directory</cite> in your
namespace).</p></li>
<li><p><strong>max_shard_size</strong> (<cite>int</cite> or <cite>str</cite>, <em>optional</em>, defaults to <cite>“10GB”</cite>) – <p>The maximum size for a checkpoint before being sharded. Checkpoints shard will then be each of size
lower than this size. If expressed as a string, needs to be digits followed by a unit (like <cite>“5MB”</cite>).</p>
<p>&lt;Tip warning={true}&gt;</p>
<p>If a single weight of the model is bigger than <cite>max_shard_size</cite>, it will be in its own checkpoint shard
which will be bigger than <cite>max_shard_size</cite>.</p>
<p>&lt;/Tip&gt;</p>
</p></li>
<li><p><strong>safe_serialization</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>) – Whether to save the model using <cite>safetensors</cite> or the traditional PyTorch way (that uses <cite>pickle</cite>).</p></li>
<li><p><strong>variant</strong> (<cite>str</cite>, <em>optional</em>) – If specified, weights are saved in the format pytorch_model.&lt;variant&gt;.bin.</p></li>
<li><p><strong>token</strong> (<cite>str</cite> or <cite>bool</cite>, <em>optional</em>) – The token to use as HTTP bearer authorization for remote files. If <cite>True</cite>, or not specified, will use
the token generated when running <cite>huggingface-cli login</cite> (stored in <cite>~/.huggingface</cite>).</p></li>
<li><p><strong>save_peft_format</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>True</cite>) – For backward compatibility with PEFT library, in case adapter weights are attached to the model, all
keys of the state dict of adapters needs to be pre-pended with <cite>base_model.model</cite>. Advanced users can
disable this behaviours by setting <cite>save_peft_format</cite> to <cite>False</cite>.</p></li>
<li><p><strong>kwargs</strong> (<cite>Dict[str, Any]</cite>, <em>optional</em>) – Additional key word arguments passed along to the [<cite>~utils.PushToHubMixin.push_to_hub</cite>] method.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.get_tokenizer">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_tokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/recwizard/modules/llm/modeling_chatgpt_gen.html#ChatgptGen.get_tokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.get_tokenizer" title="Permalink to this definition">#</a></dt>
<dd><p>Get a tokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the tokenizer.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>(<a class="reference internal" href="#recwizard.modules.llm.tokenizer_chatgpt.ChatgptTokenizer" title="recwizard.modules.llm.tokenizer_chatgpt.ChatgptTokenizer">ChatgptTokenizer</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.response">
<span class="sig-name descname"><span class="pre">response</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.response" title="Permalink to this definition">#</a></dt>
<dd><p>Generate a template to response the processed user’s input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>raw_input</strong> (<em>str</em>) – The user’s raw input.</p></li>
<li><p><strong>tokenizer</strong> (<a class="reference internal" href="../../baseclass/tokenizer.html#recwizard.tokenizer_utils.BaseTokenizer" title="recwizard.tokenizer_utils.BaseTokenizer"><em>BaseTokenizer</em></a><em>, </em><em>optional</em>) – A tokenizer to process the raw input.</p></li>
<li><p><strong>recs</strong> (<em>list</em><em>, </em><em>optional</em>) – The recommended movies.</p></li>
<li><p><strong>max_tokens</strong> (<em>int</em>) – The maximum number of tokens used for ChatGPT API.</p></li>
<li><p><strong>temperature</strong> (<em>float</em>) – The temperature value used for ChatGPT API.</p></li>
<li><p><strong>model_name</strong> (<em>str</em><em>, </em><em>optional</em>) – The specified GPT model’s name.</p></li>
<li><p><strong>return_dict</strong> (<em>bool</em>) – Whether to return a dict or a list.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The template to response the processed user’s input.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">recwizard.modules.llm.modeling_chatgpt_rec.</span></span><span class="sig-name descname"><span class="pre">ChatgptRec</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="general.html#recwizard.modules.llm.configuration_llm_rec.LLMRecConfig" title="recwizard.modules.llm.configuration_llm_rec.LLMRecConfig"><span class="pre">LLMRecConfig</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/recwizard/modules/llm/modeling_chatgpt_rec.html#ChatgptRec"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec" title="Permalink to this definition">#</a></dt>
<dd><p>The recommender implemented based on OpanAI’s GPT models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="general.html#recwizard.modules.llm.configuration_llm_rec.LLMRecConfig" title="recwizard.modules.llm.configuration_llm_rec.LLMRecConfig"><span class="pre">LLMRecConfig</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/recwizard/modules/llm/modeling_chatgpt_rec.html#ChatgptRec.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.__init__" title="Permalink to this definition">#</a></dt>
<dd><p>Initializes the instance based on the config file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<em>ChatgptRecConfig</em>) – The config file.</p></li>
<li><p><strong>prompt</strong> (<em>str</em><em>, </em><em>optional</em>) – A prompt to override the prompt from config file.</p></li>
<li><p><strong>model_name</strong> (<em>str</em><em>, </em><em>optional</em>) – The specified GPT model’s name.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.from_pretrained">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained_model_name_or_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/recwizard/modules/llm/modeling_chatgpt_rec.html#ChatgptRec.from_pretrained"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.from_pretrained" title="Permalink to this definition">#</a></dt>
<dd><p>Get an instance of this class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> – </p></li>
<li><p><strong>pretrained_model_name_or_path</strong> – </p></li>
<li><p><strong>prompt</strong> (<em>str</em><em>, </em><em>optional</em>) – The prompt to override the prompt from config file.</p></li>
<li><p><strong>model_name</strong> (<em>str</em><em>, </em><em>optional</em>) – The specified GPT model’s name.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the instance.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(<a class="reference internal" href="#recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec" title="recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec">ChatgptRec</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.save_pretrained">
<span class="sig-name descname"><span class="pre">save_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_directory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">PathLike</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">push_to_hub</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/recwizard/modules/llm/modeling_chatgpt_rec.html#ChatgptRec.save_pretrained"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.save_pretrained" title="Permalink to this definition">#</a></dt>
<dd><p>Save a model and its configuration file to a directory, so that it can be re-loaded using the
[<cite>~PreTrainedModel.from_pretrained</cite>] class method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_directory</strong> (<cite>str</cite> or <cite>os.PathLike</cite>) – Directory to which to save. Will be created if it doesn’t exist.</p></li>
<li><p><strong>is_main_process</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>True</cite>) – Whether the process calling this is the main process or not. Useful when in distributed training like
TPUs and need to call this function on all processes. In this case, set <cite>is_main_process=True</cite> only on
the main process to avoid race conditions.</p></li>
<li><p><strong>state_dict</strong> (nested dictionary of <cite>torch.Tensor</cite>) – The state dictionary of the model to save. Will default to <cite>self.state_dict()</cite>, but can be used to only
save parts of the model or if special precautions need to be taken when recovering the state dictionary
of a model (like when using model parallelism).</p></li>
<li><p><strong>save_function</strong> (<cite>Callable</cite>) – The function to use to save the state dictionary. Useful on distributed training like TPUs when one
need to replace <cite>torch.save</cite> by another method.</p></li>
<li><p><strong>push_to_hub</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>) – Whether or not to push your model to the Hugging Face model hub after saving it. You can specify the
repository you want to push to with <cite>repo_id</cite> (will default to the name of <cite>save_directory</cite> in your
namespace).</p></li>
<li><p><strong>max_shard_size</strong> (<cite>int</cite> or <cite>str</cite>, <em>optional</em>, defaults to <cite>“10GB”</cite>) – <p>The maximum size for a checkpoint before being sharded. Checkpoints shard will then be each of size
lower than this size. If expressed as a string, needs to be digits followed by a unit (like <cite>“5MB”</cite>).</p>
<p>&lt;Tip warning={true}&gt;</p>
<p>If a single weight of the model is bigger than <cite>max_shard_size</cite>, it will be in its own checkpoint shard
which will be bigger than <cite>max_shard_size</cite>.</p>
<p>&lt;/Tip&gt;</p>
</p></li>
<li><p><strong>safe_serialization</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>) – Whether to save the model using <cite>safetensors</cite> or the traditional PyTorch way (that uses <cite>pickle</cite>).</p></li>
<li><p><strong>variant</strong> (<cite>str</cite>, <em>optional</em>) – If specified, weights are saved in the format pytorch_model.&lt;variant&gt;.bin.</p></li>
<li><p><strong>token</strong> (<cite>str</cite> or <cite>bool</cite>, <em>optional</em>) – The token to use as HTTP bearer authorization for remote files. If <cite>True</cite>, or not specified, will use
the token generated when running <cite>huggingface-cli login</cite> (stored in <cite>~/.huggingface</cite>).</p></li>
<li><p><strong>save_peft_format</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>True</cite>) – For backward compatibility with PEFT library, in case adapter weights are attached to the model, all
keys of the state dict of adapters needs to be pre-pended with <cite>base_model.model</cite>. Advanced users can
disable this behaviours by setting <cite>save_peft_format</cite> to <cite>False</cite>.</p></li>
<li><p><strong>kwargs</strong> (<cite>Dict[str, Any]</cite>, <em>optional</em>) – Additional key word arguments passed along to the [<cite>~utils.PushToHubMixin.push_to_hub</cite>] method.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.get_tokenizer">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_tokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/recwizard/modules/llm/modeling_chatgpt_rec.html#ChatgptRec.get_tokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.get_tokenizer" title="Permalink to this definition">#</a></dt>
<dd><p>Get a tokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the tokenizer.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>(ChatgptRecTokenizer)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.response">
<span class="sig-name descname"><span class="pre">response</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.response" title="Permalink to this definition">#</a></dt>
<dd><p>Generate a template to response the processed user’s input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>raw_input</strong> (<em>dict</em>) – A dict that contains the question and its related information.</p></li>
<li><p><strong>tokenizer</strong> (<a class="reference internal" href="../../baseclass/tokenizer.html#recwizard.tokenizer_utils.BaseTokenizer" title="recwizard.tokenizer_utils.BaseTokenizer"><em>BaseTokenizer</em></a><em>, </em><em>optional</em>) – A tokenizer to process the question.</p></li>
<li><p><strong>topk</strong> (<em>int</em>) – The number of answers.</p></li>
<li><p><strong>max_tokens</strong> (<em>int</em>) – The maximum number of tokens used for ChatGPT API.</p></li>
<li><p><strong>temperature</strong> (<em>float</em>) – The temperature value used for ChatGPT API.</p></li>
<li><p><strong>model_name</strong> (<em>str</em><em>, </em><em>optional</em>) – The specified GPT model’s name.</p></li>
<li><p><strong>return_dict</strong> (<em>bool</em>) – Whether to return a dict or a list.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The answers.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="recwizard.modules.llm.tokenizer_chatgpt.ChatgptTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">recwizard.modules.llm.tokenizer_chatgpt.</span></span><span class="sig-name descname"><span class="pre">ChatgptTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/recwizard/modules/llm/tokenizer_chatgpt.html#ChatgptTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#recwizard.modules.llm.tokenizer_chatgpt.ChatgptTokenizer" title="Permalink to this definition">#</a></dt>
<dd><p>The tokenizer for the generator based on OpenAI’s GPT models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="recwizard.modules.llm.tokenizer_chatgpt.ChatgptTokenizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/recwizard/modules/llm/tokenizer_chatgpt.html#ChatgptTokenizer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#recwizard.modules.llm.tokenizer_chatgpt.ChatgptTokenizer.__init__" title="Permalink to this definition">#</a></dt>
<dd><p>Initializes the instance of this tokenizer.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="recwizard.modules.llm.tokenizer_chatgpt.ChatgptTokenizer.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/recwizard/modules/llm/tokenizer_chatgpt.html#ChatgptTokenizer.__call__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#recwizard.modules.llm.tokenizer_chatgpt.ChatgptTokenizer.__call__" title="Permalink to this definition">#</a></dt>
<dd><p>Process the raw input by extracting the pure text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>context</strong> (<em>str</em>) – The raw input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict that contains the extracted text.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(dict)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="llama.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Llama</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="general.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">General LLM</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, McAuley Lab
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">ChatGPT</a><ul>
<li><a class="reference internal" href="#recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen"><code class="docutils literal notranslate"><span class="pre">ChatgptGen</span></code></a><ul>
<li><a class="reference internal" href="#recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.__init__"><code class="docutils literal notranslate"><span class="pre">ChatgptGen.__init__()</span></code></a></li>
<li><a class="reference internal" href="#recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.from_pretrained"><code class="docutils literal notranslate"><span class="pre">ChatgptGen.from_pretrained()</span></code></a></li>
<li><a class="reference internal" href="#recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.save_pretrained"><code class="docutils literal notranslate"><span class="pre">ChatgptGen.save_pretrained()</span></code></a></li>
<li><a class="reference internal" href="#recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.get_tokenizer"><code class="docutils literal notranslate"><span class="pre">ChatgptGen.get_tokenizer()</span></code></a></li>
<li><a class="reference internal" href="#recwizard.modules.llm.modeling_chatgpt_gen.ChatgptGen.response"><code class="docutils literal notranslate"><span class="pre">ChatgptGen.response()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec"><code class="docutils literal notranslate"><span class="pre">ChatgptRec</span></code></a><ul>
<li><a class="reference internal" href="#recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.__init__"><code class="docutils literal notranslate"><span class="pre">ChatgptRec.__init__()</span></code></a></li>
<li><a class="reference internal" href="#recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.from_pretrained"><code class="docutils literal notranslate"><span class="pre">ChatgptRec.from_pretrained()</span></code></a></li>
<li><a class="reference internal" href="#recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.save_pretrained"><code class="docutils literal notranslate"><span class="pre">ChatgptRec.save_pretrained()</span></code></a></li>
<li><a class="reference internal" href="#recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.get_tokenizer"><code class="docutils literal notranslate"><span class="pre">ChatgptRec.get_tokenizer()</span></code></a></li>
<li><a class="reference internal" href="#recwizard.modules.llm.modeling_chatgpt_rec.ChatgptRec.response"><code class="docutils literal notranslate"><span class="pre">ChatgptRec.response()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#recwizard.modules.llm.tokenizer_chatgpt.ChatgptTokenizer"><code class="docutils literal notranslate"><span class="pre">ChatgptTokenizer</span></code></a><ul>
<li><a class="reference internal" href="#recwizard.modules.llm.tokenizer_chatgpt.ChatgptTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">ChatgptTokenizer.__init__()</span></code></a></li>
<li><a class="reference internal" href="#recwizard.modules.llm.tokenizer_chatgpt.ChatgptTokenizer.__call__"><code class="docutils literal notranslate"><span class="pre">ChatgptTokenizer.__call__()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js?v=57cfd03c"></script>
    <script src="../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../../../_static/scripts/furo.js?v=32e29ea5"></script>
    <script src="../../../_static/design-tabs.js?v=36754332"></script>
    </body>
</html>